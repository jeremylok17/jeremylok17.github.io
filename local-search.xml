<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Deepmind全能选手&quot;Gato&quot;</title>
    <link href="/2022/06/21/Deepmind%E5%85%A8%E8%83%BD%E9%80%89%E6%89%8BGato/"/>
    <url>/2022/06/21/Deepmind%E5%85%A8%E8%83%BD%E9%80%89%E6%89%8BGato/</url>
    
    <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><blockquote><p>在写文章、画图之后，AI 大模型现在又同时有了打游戏的能力。不禁在想，强AI还远吗？</p></blockquote><p>如果能使用统一的序列模型就能解决所有任务，就能解决很多不必要的麻烦。近日，受大规模语言建模的启发，Deepmind用类似的方法构造了一个通用智能体<strong>Gato</strong>，它具有多模态、多任务、多具身的特点。</p><p>既然是多任务，就需要涉及到不同类型的数据，如何将这些数据“一视同仁”地作为训练数据输入到模型中呢？为了统一处理多模态数据，Deepmind将所有数据序列化为一个扁平的token序列。在此表示中，Gato会根据上下文将token组合成动作、文字、像素等信息。</p><h2 id="训练细节"><a href="#训练细节" class="headerlink" title="训练细节"></a>训练细节</h2><p>在 Gato 的训练阶段，来自不同任务和模态的数据被序列化为扁平的 token 序列，由一个类似于大型语言模型的 transformer 神经网络进行 batch 和其他处理。由于损失被 masked，Gato 只预测动作和文本目标。<br><img src="/img/Gato/pic3.jpg" alt="训练流程"><br>在部署 Gato 时，提示（如演示）被 tokenised，形成了初始序列。接着，环境产生了首个观察结果，该结果也被 tokenised 并添加到序列中。Gato 以自回归的方式对动作向量进行采样，一次只采样一个 token。</p><p>一旦包含动作向量的所有 token 都被采样（由环境的动作规范确定），动作被解码并发送给环境，然后逐步产生新的观察结果。重复这一过程。Gato 模型始终在包含 1024 个 token 的上下文环境窗口内查看之前所有的观察结果和动作。‍下图展示了将 Gato 部署为控制策略（control policy）的流程。<br><img src="/img/Gato/pic4.jpg" alt="训练流程"></p><h2 id="训练难度"><a href="#训练难度" class="headerlink" title="训练难度"></a>训练难度</h2><p>相比有 1750 亿参数的 GPT-3，Gato 要小很多，只有约 12 亿个参数。而且，其建设基础非常简洁，只依赖于一个 Transformer 架构。</p><p>研究人员在将 Gato 与另外两个分别有 7900 万、3.64 亿参数模型的所有基准任务平均分数，进行比较后发现，对于等效的令牌计数，随着规模的增加，AI 性能会显著提高。更大的 Gato 模型可以使用更多数据进行训练，并可能更好地执行各种任务。</p><p>大概这是第一个CV、NLP、RL的结合体？</p><p>see you~</p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>多模态</tag>
      
      <tag>Deepmind</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>三年的蛰伏，以及迟到了七年的FMVP</title>
    <link href="/2022/06/20/first-post/"/>
    <url>/2022/06/20/first-post/</url>
    
    <content type="html"><![CDATA[<p>2022年6月17日，波士顿花园终场哨声响起，勇士又一次捧起了奥布莱恩杯，值得一提的是2015年勇士夺冠也是在6月17日。 只不过这一次库里没有用力把篮球扔向天空，当年那群意气风发的小伙子，现在已经变成定海神针般的老将，他们成为了球队老大哥、成为了丈夫、成为了父亲。</p><span id="more"></span><h2 id="遗憾"><a href="#遗憾" class="headerlink" title="遗憾"></a>遗憾</h2><p>2015年6月17日，同样客场夺冠，同样4-2结束比赛，当宣布伊戈达拉为总决赛MVP的时候，库里依然激动地为队友欢呼。那时候我在想，没事，反正核心阵容都还年轻，薪资机构也很健康，未来有的是机会。<br>后来的故事大家都知道了，16年3-1被翻盘，17、18年杜兰特加盟勇士并两连FMVP，19年克莱、杜兰特、考辛斯、鲁尼接连伤退，20年库里报销、球队摆烂，21年克莱二次重伤、怀斯曼报销，库里独木难支，在附加赛遭遇两连败，连续两年无缘季后赛。。。</p><h2 id="重来"><a href="#重来" class="headerlink" title="重来"></a>重来</h2><p>曾经的防守大闸老的老，走的走，退役的退役，没办法，库里身为老大哥只能以身作则练好防守，不管是从态度上还是行动上。于是我们可以看到本赛季的库里很少有以前着急下手的坏习惯，轻型小前锋已经无法点名他了——曾经那个球场精灵渐渐成了重剑无锋的娃娃脸肌肉男。<br>本赛季勇士队取得了联盟第三的战绩，但是库里从赛季中期开始手感一直不佳。有人发问：是不是勇士的体系成就了库里，库里是不是吃了团队的红利？ 这一切质疑随着季后赛的到来都化为云烟。<br>季后赛首轮，面对防守称不上优秀的丹佛掘金，普尔格林等队员还能在进攻端惩戒对方。但是到了次轮与灰熊队的肉搏战，人们发现，寄予众望的普尔只能一头扎进人堆等待失误或者被封盖，防守大闸格林面对对方一堆肌肉跳跳男也显得有些无力，生死时刻，勇士队还是只能指望库里。关键时刻，库里一次次的杀入内线——用速度过掉或者顶开防守人。最终勇士有惊无险地淘汰灰熊（虽然有过55分惨案）。 西决，勇士干净利落地淘汰了077带领的独行侠，双方倒是和和睦睦，似乎都提前知道结果是什么。</p><h2 id="登顶"><a href="#登顶" class="headerlink" title="登顶"></a>登顶</h2><p>如果说分区比赛是库里和勇士队其他球员互相支持，那么总决赛的前四场比赛可以称得上是库里孤独carry的代表作。面对本赛季DPOY斯玛特，防守联盟第二的凯尔特人，库里在前四场场均轰下34分左右，有质有量。即使这样，勇士也只是取得了2-2的战绩。第四场，面临扳平或者1-3的场面，库里砍下43+10，里突外投，从此以后，”关键时刻掉链子”和库里再也无关。<br>G5、G6勇士一鼓作气全都拿下，库里也终于获得了属于自己的FMVP。G6最后有一幕打动了我，比赛时间还剩下一个多回合，库里已经去底线与戴尔库里拥抱致意，因为转播角度的原因，之前我只看到了库里的背影，然后库里转过身来手撑身子、头朝下颤抖着，我看了这么多年的库里，那一刻我以为他是笑的颤抖，可等他抬起头的那一刻，我看到了他的泪水。就像情绪会沿着网线传染，我的眼眶也已湿润，明明是一支与我无关的球队，明明是一名与我素不相识的球员，因为他们的团结，因为他的坚守，我也为他们感动。</p><h2 id="关于友谊"><a href="#关于友谊" class="headerlink" title="关于友谊"></a>关于友谊</h2><p>还有一点非常有趣，比赛的最后时刻又是伊戈达拉将球从凯尔特人队员手中要来，然后送给库里。为什么要说又？2015年总决赛G6最后一刻，库里激动的将球抛向天空，苦了伊戈达拉满场追球。这可能是伊戈达拉最后一场比赛了，曾经飞天入地的小AI，如今场均只能登场1、2分钟，当个吉祥物。从此以后，库里正式成为了勇士队中年龄最大的球员。</p><center>斯蒂芬，球拿好，以后的路自己走了！</center><p><img src="/img/%E6%9D%82%E8%B0%881/pic3.png"><br><img src="/img/%E6%9D%82%E8%B0%881/pic4.png"></p>]]></content>
    
    
    <categories>
      
      <category>杂谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>勇士</tag>
      
      <tag>篮球</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
